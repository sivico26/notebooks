{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pipeline de ensamble de genomas con nanopore**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los pasos generales para un ensamble son:\n",
    "\n",
    "![Pasos](https://raw.githubusercontent.com/sivico26/notebooks/master/Pipeline/Images/steps.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El workflow en breve:\n",
    "\n",
    "- Basecalling\n",
    "- Basecall QC\n",
    "- Read-read overlap\n",
    "- (¿Corrección de error?)\n",
    "- Ensamble (Guiado o de novo)\n",
    "- Read mapping\n",
    "- Polishing (Nanopolish, ¿PoreSeq?)\n",
    "- Assembly QC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Basecalling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen Basecallers basados en HMM(*e.g.* Nanocall) y otros basados en RNN(*e.g.* Scrappie). En comparación las RNN no hacen ninguna suposición de longitud de la secuencia y no son afectados por repeticiones en la secuencia. Aún así, es un reto determinar la longitud real de homopolimeros (*e.g.* AAAAAAAAAAA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro de los basecallers que se podrían considerar para el pipeline dada una muy buena [comparación](https://github.com/rrwick/Basecalling-comparison) concluimos que __Albacore__ es por ahora la mejor opción disponible. No vale la pena incorporar otros basecallers si no hay diferencias significativas. Ahora, __Guppy__ podría considerarse ya que hace lo mismo que __Albacore__ pero está diseñado para aprovechar GPU, por lo que es mucho más rápido si puede acceder a este recurso (Nota: Guppy no soporta demultiplexado). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** Scrappy y Nanocall (y muy probablemente Albacore), al paralelizar aumentan linealmente su velocidad, para también el uso de memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que darle la oportunidad a Chiron? No, por lento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! read_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Read-read overlap**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La contienda **Minimap vs Graphmap** la gana de lejos Minimap (misma precisión, 2.5x más rápído y usa 4.6x menos memoria), y eso sin contar que minimap ya va en **Minimap2**.\n",
    "<br>\n",
    "Por su parte, como lo apunto Heng-Li en su [blog](http://lh3.github.io/2018/04/02/minimap2-and-the-future-of-bwa) BWA-MEM funciona muy bien con los reads cortos de Illumina, y en este campo es cuestionable si Minimap2 lo bate en este sentido, pero para reads largos, Minimap2 es el indicado. \n",
    "<br>\n",
    "En conclusión: ¿Qué algoritmo usar? $\\rightarrow$ Distribución de Reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Dónde queda **Minialign**? No está referenciado aún vs Minimap2. Sospechamos que es más rápido y más impreciso, pero hay que evaluarlo.\n",
    "\n",
    "BWA-MEM: genera SAMs <br>\n",
    "Minimap2: genera PAFs y SAMs\n",
    "\n",
    "Minimap es mucho más rápido que BWA-MEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** El multithreading de Minimap2(Curva verde) aumenta la velocidad del algoritmo, pero llega a un máximo y luego la velocidad vuelve a disminuir. Esto ocurre por la sincronización del overhead en los múltiples threads. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Multithreading_minimap](https://raw.githubusercontent.com/sivico26/notebooks/master/Pipeline/Images/minimap_parallelizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Assembly**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Canu** es ~1096x más lento que **Miniasm**, pero más impreciso también. Esto es por la corrección de error que hace Canu (muy pesada computacionalmente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluar Canu vs FALCON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Polishing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es **mandatorio** usar Nanopolish (o en general, hacer polishing), y hacerlo con la opción de ```--methylation-aware dcm,dca```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Medaka__ es más rápido que __Nanopolish__, aunque corrige menos el error. Debido a que no evalua la raw signal, así que se puede considerar en casos de premura o en los que no se cuente con los fast5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nanopolish: solo acepta SAM como entrada y los fast5 **(Revisar actualización)**\n",
    "<br>\n",
    "Racon: acepta SAM y PAF, pero requiere los fastq "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que si se va a usar Racon, es mejor usar Minimap para mapear (ligeramente), usar formato SAM mejora usa menos memoria que "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** No usar hyperthreading con Nanopolish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Notas Generales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Si se va a utilizar Nanonpolish, no ensamblar con miniasm (utilizar Canu), termina siendo más lento el proceso completo\n",
    "- Ensamble rápido $\\rightarrow$ Miniasm + Racon\n",
    "- Ensamble preciso $\\rightarrow$ Canu + Nanopolish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Criterios para selección de Pipeliner**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Que siga un estándar\n",
    "- Que sea fácil de usar\n",
    "- Que sea \"montable\" en el biohub\n",
    "- Que sea fácil de modificar\n",
    "- Que sea escalable\n",
    "- Que sea paralizable\n",
    "- Que utilice checkpoints\n",
    "- Que esté bien documentado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basados en esta [lista](https://github.com/pditommaso/awesome-pipeline) y filtrando por herramientas pensadas para bioinformática:\n",
    "\n",
    "- [Antha](https://www.antha-lang.org/) (Es visual, se ve muy llamativo para edición. Trabaja Java[creo])\n",
    "- [Biomake](https://github.com/evoldoers/biomake) (Interesante, pero hay que aprender Prolog)\n",
    "- [BioQueue](https://github.com/liyao001/BioQueue) (Asignación de recursos más eficiente a los programas. No parece un entorno que facilite deasarrollar pipelines)\n",
    "- [BPipe](https://github.com/ssadedin/bpipe/) (Dicen ser la herramienta más fácil de usar \"No Programming knowledge required\". No aparenta tener un manejo sencillo de parámetros)\n",
    "- [Cluster Flow](http://clusterflow.io/) (Similar a BPipe e que se enfocan en facilidad sacrificando poder de desarrollo. Ambos parecen bastante estructurados y manejables una vez construido el pipeline (Pero CF parece más bioinformático, pre-built))\n",
    "- [Dagr](https://github.com/fulcrumgenomics/dagr)\n",
    "- [Loom](https://github.com/StanfordBioinformatics/loom)\n",
    "- [Moa](https://github.com/mfiers/Moa)\n",
    "- [Nextflow](http://www.nextflow.io/) (Hasta ahora la más atractiva. Entre muchas cosas, portable)\n",
    "- [Rubra](https://github.com/bjpop/rubra)\n",
    "- [Ruffus](http://www.ruffus.org.uk/)\n",
    "- [Snakemake](https://bitbucket.org/johanneskoester/snakemake/wiki/Home)\n",
    "- [Luigi](https://github.com/spotify/luigi) (Desarrollado por Spotify. Bastante enfocada a Hadoop. Visual.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Programa | Modificable | Usable | Estándar | Biohub | Escalable | Checkpoints |\n",
    "| -- | -- | -- | -- | -- | -- | -- |\n",
    "| Snakemake | 3 | x | Make | Sí | Sí | Sí |\n",
    "| Nextflow  | 4 | x | Groovy | Sí | Sí | Sí | \n",
    "| Bpipe     | 5 | 5 | Groovy | Sí |  No  | Sí | \n",
    "| Luigi     |   |   | Python | Sí | Sí | Sí |\n",
    "| Cluster Flow  | 5 | 5 | Bash | Sí | Sí | Sí |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Luigi     |   |   |    |    |    | |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
