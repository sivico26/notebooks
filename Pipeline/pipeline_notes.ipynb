{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pipeline de ensamble de genomas con nanopore**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El workflow en breve:\n",
    "\n",
    "- Basecalling\n",
    "- Basecall QC\n",
    "- Read-read overlap\n",
    "- (¿Corrección de error?)\n",
    "- Ensamble (Guiado o de novo)\n",
    "- Read mapping\n",
    "- Polishing (Nanopolish, ¿PoreSeq?)\n",
    "- Assembly QC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Basecalling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen Basecallers basados en HMM(*e.g.* Nanocall) y otros basados en RNN(*e.g.* Scrappie). En comparación las RNN no hacen ninguna suposición de longitud de la secuencia y no son afectados por repeticiones en la secuencia. Aún así, es un reto determinar la longitud real de homopolimeros (*e.g.* AAAAAAAAAAA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro de los basecallers que se podrían considerar para el pipeline dada una muy buena [comparación](https://github.com/rrwick/Basecalling-comparison) concluimos que __Albacore__ es por ahora la mejor opción disponible. No vale la pena incorporar otros basecallers si no hay diferencias significativas. Ahora, __Guppy__ podría considerarse ya que hace lo mismo que __Albacore__ pero está diseñado para aprovechar GPU, por lo que es mucho más rápido si puede acceder a este recurso (Nota: Guppy no soporta demultiplexado). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** Scrappy y Nanocall (y muy probablemente Albacore), al paralelizar aumentan linealmente su velocidad, para también el uso de memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Read-read overlap**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La contienda **Minimap vs Graphmap** la gana de lejos Minimap (misma precisión, 2.5x más rápído y usa 4.6x menos memoria), y eso sin contar que minimap ya va en **Minimap2**.\n",
    "<br>\n",
    "Por su parte, como lo apunto Heng-Li en su [blog](http://lh3.github.io/2018/04/02/minimap2-and-the-future-of-bwa) BWA-MEM funciona muy bien con los reads cortos de Illumina, y en este campo es cuestionable si Minimap2 lo bate en este sentido, pero para reads largos, Minimap2 es el indicado. \n",
    "<br>\n",
    "En conclusión: ¿Qué algoritmo usar? $\\rightarrow$ Distribución de Reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Dónde queda **Minialign**? No está referenciado aún vs Minimap2. Sospechamos que es más rápido y más impreciso, pero hay que evaluarlo.\n",
    "\n",
    "BWA-MEM: genera SAMs <br>\n",
    "Minimap2: genera PAFs y SAMs\n",
    "\n",
    "Minimap es mucho más rápido que BWA-MEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** El multithreading de Minimap2(Curva verde) aumenta la velocidad del algoritmo, pero llega a un máximo y luego la velocidad vuelve a disminuir. Esto ocurre por la sincronización del overhead en los múltiples threads. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Multithreading_minimap](Images/minimap_parallelizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Assembly**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Canu** es ~1096x más lento que **Miniasm**, pero más impreciso también. Esto es por la corrección de error que hace Canu (muy pesada computacionalmente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Polishing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es **mandatorio** usar Nanopolish (o en general, hacer polishing), y hacerlo con la opción de ```--methylation-aware dcm,dca```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Medaka__ es más rápido que __Nanopolish__, aunque corrige menos el error. Debido a que no evalua la raw signal, así que se puede considerar en casos de premura o en los que no se cuente con los fast5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nanopolish: solo acepta SAM como entrada y los fast5 **(Revisar actualización)**\n",
    "<br>\n",
    "Racon: acepta SAM y PAF, pero requiere los fastq "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que si se va a usar Racon, es mejor usar Minimap para mapear (ligeramente), usar formato SAM mejora usa menos memoria que "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** No usar hyperthreading con Nanopolish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Notas Generales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Si se va a utilizar Nanonpolish, no ensamblar con miniasm (utilizar Canu), termina siendo más lento el proceso completo\n",
    "- Ensamble rápido $\\rightarrow$ Miniasm + Racon\n",
    "- Ensamble preciso $\\rightarrow$ Canu + Nanopolish"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
